# Plasma Control for Tokamak Fusion Plasma Using Reinforcement Learning

This project simulates a **150-second plasma discharge** in the **ITER tokamak** (see [ITER overview](https://en.wikipedia.org/wiki/ITER)). We seek to use reinforcement learning (RL) to demonstrate control of the plasma over these 150 seconds by achieving certain objectives while avoiding potential instabilities and disruptions, all in real-time. Our RL agent has control over some levers that a real tokamak controller will have access to and only has the same visibility into the state of the plasma that a real tokamak, based on diagnostics sensors, would be able to see.

---

## ðŸš€ Project Description

Magnetic confinement fusion in a tokamak depends on precisely controlling plasma shape, current, temperature, and stability. In this project, we simulate a hypothetical ITER plasma discharge lasting **150 seconds** and evaluate whether a modern RL controller can:

- Maintain plasma shape and position  
- Maximize fusion power output  
- Avoid disruptions and unstable operating regions  
- Operate with fast, real-time inference  
- Learn robust control policies under **partial observability**

The RL agent interacts with a tokamak simulation environment (e.g., `Gym_TORAX_IterHybrid-v0`) built to emulate realistic actuator constraints, diagnostic measurements, plasma behavior, and stability boundaries.

---

## ðŸ•¹ Action Space

The RL agent can control several actuators commonly used in tokamak operation. These parameters, taken from **`Gym_TORAX_IterHybrid-v0_env - Action Space.csv`**, include:

### 1. **Plasma Current Control (Central Solenoid)**
Tokamak control requires cooperation between external magnetic coils and a strong **toroidal plasma current** driven by the central solenoid.

- **Control:** Plasma current (Ip) ramping  
- **Purpose:** Maintain plasma shape and assist magnetic confinement  
- **Constraints:**  
  - Range: **0 â†’ 15 MA**  
  - Max ramp-up: **0.2 MA/s**

---

### 2. **Neutral Beam Injection (NBI)**
NBI injects high-energy neutral particles into the plasma, heating it and helping reach **burning plasma** conditions.

- **Control:**  
  - Total NBI power  
  - Two deposition profile parameters  
- **Purpose:** Heating, current drive, and shaping of pressure profiles  
- **Constraints:**  
  - Power: **0 â†’ 33 MW**  
  - Deposition params: **0 â†’ 1**

---

### 3. **Electron Cyclotron Resonance Heating (ECRH)**
Microwave heating mechanism used for precise electron heating and stability control.

- **Control:**  
  - Total ECRH power  
  - Two deposition profile parameters  
- **Purpose:** Local heating, sawtooth control, stabilization of MHD modes  
- **Constraints:**  
  - Power: **0 â†’ 20 MW**  
  - Deposition params: **0 â†’ 1**

---

## ðŸ“¡ State Space

The state space, described in **`Gym_TORAX_IterHybrid-v0_env - State Space.csv`**, includes roughly **150 scalar and vector variables** representing:

- Magnetic geometry  
- Temperature and density profiles  
- Transport and diffusion parameters  
- Plasma equilibrium and shaping  
- Confinement and stability metrics  

However, **only a subset** of these state parameters is visible to the RL agentâ€”specifically, those measurable in a realistic tokamak experiment via diagnostics (magnetic coils, interferometers, bolometers, etc.).

The agent must therefore learn a policy under **partial observability**, making the task significantly more complex and more realistic.

---

## ðŸ§  Reinforcement Learning Algorithm

**The RL algorithm is TBD**, with current candidates including:

- **Soft Actor-Critic (SAC)** â€“ continuous actions, entropy-regularized, sample-efficient  
- **Proximal Policy Optimization (PPO)** â€“ stable on-policy algorithm widely used in control problems  

The final choice will depend on performance under real-time constraints and stability in high-dimensional state/action spaces.

---

## ðŸŽ¯ Objectives

The RL controller aims to:

### âœ” **1. Maintain Plasma Shape and Magnetic Equilibrium**
Keep plasma within desired boundaries and avoid drift or loss of confinement.

### âœ” **2. Maximize Fusion Power Output**
Steer thermodynamic and geometric conditions toward high performance while avoiding over-driving.

### âœ” **3. Avoid Major Disruptions**
Disruptions happen on millisecond timescales and pose severe risk to tokamak hardware.  
The policy must avoid known disruptive conditions such as:

- **Safety factor** \( q < 1 \) â€” associated with sawtooth crashes and internal kinks  
- **Greenwald fraction** \( f_G \rightarrow 1 \) â€” density-limit disruptions  

Fast inference is essential: **control decisions must be made quickly enough to react to developing instabilities**.

---

## ðŸ“‚ Repository Structure (proposed)

```text
/
â”œâ”€â”€ env/                        # Gym environment wrapper
â”œâ”€â”€ actions/                    # Action space definitions and scaling
â”œâ”€â”€ state_space/                # State visibility masks and processing
â”œâ”€â”€ simulations/                # tokamak simulation tools
â”œâ”€â”€ algorithms/                 # PPO/SAC implementations
â”œâ”€â”€ experiments/                # scripts + notebooks for training + eval
â”œâ”€â”€ results/                    # saved checkpoints, logs, metrics
â””â”€â”€ README.md
